{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4d5cab6-515e-4dd6-95ae-6393f0c4435c",
   "metadata": {},
   "source": [
    "## Ingesting PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2e8b999-83ba-484a-9b94-f56c201d2036",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --q unstructured langchain\n",
    "%pip install --q \"unstructured[all-docs]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c0e2f74-7c4b-4665-8d87-bc00656f31e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "104c0b18-1c06-41a1-a2ca-f9ee23f4f952",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import UnstructuredPDFLoader\n",
    "\n",
    "\n",
    "local_path = \"Mawared-full-dataset-alpaca_-Sheet1.pdf\"\n",
    "\n",
    "# Local PDF file uploads\n",
    "if local_path:\n",
    "  loader = UnstructuredPDFLoader(file_path=local_path)\n",
    "  data = loader.load()\n",
    "else:\n",
    "  print(\"Upload a PDF file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38119195-9c91-4e58-aa46-8a74244032af",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Preview first page\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mdata\u001b[49m[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mpage_content\n",
      "\u001b[1;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "# Preview first page\n",
    "data[0].page_content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2faacc1-be29-4d52-a46e-94f5b5b8e728",
   "metadata": {},
   "source": [
    "## Vector Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dcf2cfe-a7aa-4ecf-85e3-f77b9e850514",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!ollama pull nomic-embed-text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39aebbf8-92bf-42e5-951e-40bb458852d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME                    \tID          \tSIZE  \tMODIFIED       \n",
      "codellama:7b-code       \tfc84f39375bc\t3.8 GB\t2 months ago  \t\n",
      "gemma:latest            \t430ed3535049\t5.2 GB\t5 weeks ago   \t\n",
      "llama2:latest           \t78e26419b446\t3.8 GB\t2 hours ago   \t\n",
      "llama2-uncensored:latest\t44040b922233\t3.8 GB\t3 months ago  \t\n",
      "llava:latest            \t8dd30f6b0cb1\t4.7 GB\t2 months ago  \t\n",
      "mistral:latest          \t4d9f4b269c33\t4.1 GB\t3 months ago  \t\n",
      "nomic-embed-text:latest \t0a109f422b47\t274 MB\t17 seconds ago\t\n"
     ]
    }
   ],
   "source": [
    "!ollama list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "id": "5394d61f-906b-4776-b8b5-9f0045c76193",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --q chromadb\n",
    "%pip install --q langchain-text-splitters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "id": "83a39856-0cc0-4ebe-8024-9db32455a545",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import Chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "id": "bad040e2-3abe-4e23-abb9-951b223b9262",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split and chunk \n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=7500, chunk_overlap=100)\n",
    "chunks = text_splitter.split_documents(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb11c92-e732-4a88-8f57-57a19b38e383",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add to vector database\n",
    "vector_db = Chroma.from_documents(\n",
    "    documents=chunks, \n",
    "    embedding=OllamaEmbeddings(model=\"nomic-embed-text\",show_progress=True),\n",
    "    collection_name=\"local-rag\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39eadf50-2f3d-4420-8858-94e9c1682ffa",
   "metadata": {},
   "source": [
    "## Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ec338c4-f282-462f-b0a0-c1899538eb07",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate, PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain.retrievers.multi_query import MultiQueryRetriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "id": "d1d6ceeb-6883-4688-b923-e771c2b2cb07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLM from Ollama\n",
    "local_model = \"llama3.1\"\n",
    "llm = ChatOllama(model=local_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "id": "c436d5cd-5dd0-448c-b5c0-6eddab879c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "QUERY_PROMPT = PromptTemplate(\n",
    "    input_variables=[\"question\"],\n",
    "    template=\"\"\"You are an AI language model assistant. Your task is to generate five\n",
    "    different versions of the given user question to retrieve relevant documents from\n",
    "    a vector database. By generating multiple perspectives on the user question, your\n",
    "    goal is to help the user overcome some of the limitations of the distance-based\n",
    "    similarity search. Provide these alternative questions separated by newlines.\n",
    "    Original question: {question}\"\"\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "id": "71e423dc-f632-46f8-9bec-d74cb268ab74",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = MultiQueryRetriever.from_llm(\n",
    "    vector_db.as_retriever(), \n",
    "    llm,\n",
    "    prompt=QUERY_PROMPT\n",
    ")\n",
    "\n",
    "# RAG prompt\n",
    "template = \"\"\"Answer the question based ONLY on the following context:\n",
    "{context}\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "id": "cb1f308f-8472-4506-9517-d79b61d408f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = (\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "id": "915fb18b-cb57-42cf-a9b3-c6f95d3c4e32",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " what is this about?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OllamaEmbeddings: 100%|███████████████████████████| 1/1 [00:01<00:00,  1.15s/it]\n",
      "OllamaEmbeddings: 100%|███████████████████████████| 1/1 [00:00<00:00, 36.58it/s]\n",
      "OllamaEmbeddings: 100%|███████████████████████████| 1/1 [00:00<00:00, 14.64it/s]\n",
      "OllamaEmbeddings: 100%|███████████████████████████| 1/1 [00:00<00:00, 23.34it/s]\n",
      "OllamaEmbeddings: 100%|███████████████████████████| 1/1 [00:00<00:00, 23.14it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' This document is the Insight Report of The Global Cooperation Barometer 2024 by the World Economic Forum in collaboration with McKinsey & Company. It provides an analysis of the state of global cooperation across five pillars: trade and capital, innovation and technology, climate and natural capital, health and wellness, and peace and security. The report examines trends in cooperative actions and their outcomes to determine the overall level of global cooperation in each area. It also includes recommendations for leaders on how to reimagine global cooperation in a new era.'"
      ]
     },
     "execution_count": 518,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(input(\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "id": "06c25c1d-d205-409e-90a2-179d0bd7c41a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OllamaEmbeddings: 100%|███████████████████████████| 1/1 [00:01<00:00,  1.33s/it]\n",
      "OllamaEmbeddings: 100%|███████████████████████████| 1/1 [00:00<00:00, 26.36it/s]\n",
      "OllamaEmbeddings: 100%|███████████████████████████| 1/1 [00:00<00:00, 36.23it/s]\n",
      "OllamaEmbeddings: 100%|███████████████████████████| 1/1 [00:00<00:00, 49.43it/s]\n",
      "OllamaEmbeddings: 100%|███████████████████████████| 1/1 [00:00<00:00, 63.03it/s]\n",
      "OllamaEmbeddings: 100%|███████████████████████████| 1/1 [00:00<00:00, 58.14it/s]\n",
      "OllamaEmbeddings: 100%|███████████████████████████| 1/1 [00:00<00:00, 59.76it/s]\n",
      "OllamaEmbeddings: 100%|███████████████████████████| 1/1 [00:00<00:00, 56.69it/s]\n",
      "OllamaEmbeddings: 100%|███████████████████████████| 1/1 [00:00<00:00, 48.34it/s]\n",
      "OllamaEmbeddings: 100%|███████████████████████████| 1/1 [00:00<00:00, 51.85it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' The 5 pillars of global cooperation are:\\n\\n1. Trade and capital\\n2. Innovation and technology\\n3. Climate and natural capital\\n4. Health and wellness\\n5. Peace and security.'"
      ]
     },
     "execution_count": 519,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\"i want to create a new break setting\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe79f21-48aa-4820-aa9f-79f3d1a0a519",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete all collections in the db\n",
    "vector_db.delete_collection()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
